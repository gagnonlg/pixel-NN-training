# Documentation for pixel-NN-training
# louis.guillaume.gagnon@cern.ch

Here is an example to fully train an test a neural network.

The trainNN_keras.py script uses the keras framework to train a
neural network.

You will need to have keras installed on your machine. Refer to the
installation instruction at http://keras.io

Here are the options to the script:
$ python2 trainNN_keras.py --help
  usage: trainNN_keras.py [-h] --training-input TRAINING_INPUT --output OUTPUT
                        --config CONFIG
                        [--validation-fraction VALIDATION_FRACTION]
                        [--structure STRUCTURE [STRUCTURE ...]]
                        [--activation {sigmoid,tanh,relu}]
                        [--output-activation {softmax,linear}] [--l2 L2]
                        [--learning-rate LEARNING_RATE] [--momentum MOMENTUM]
                        [--batch BATCH] [--min-epochs MIN_EPOCHS]
                        [--max-epochs MAX_EPOCHS]
                        [--patience-increase PATIENCE_INCREASE]
                        [--threshold THRESHOLD] [--profile]
                        [--nbworkers NBWORKERS] [--verbose]

Refer to the _main() function at the bottom of the script for the
default values, and the train_nn() function docstring for more
documentation on the arguments.

The config files is used to tell the scripts which variables are the
inputs and which are the targets. It's also used to specify which
variable are metadata to be saved by the evalNN script - this block is
ignored when training. They are generated using the genconfig.py
script:

$ python2 genconfig.py --help
usage: genconfig.py [-h] [--sizeX SIZEX] [--sizeY SIZEY] --type
                    {number,pos1,pos2,pos3} [--old]

Workflow:

$ setupATLAS
$ lsetup root
$ python2 trainNN_keras.py --training-input $INPUT --output test  \
    --config <(python2 genconfig.py --type number)

This should create the following files:
test.model.yaml
test.normalization.txt
test.weights.hdf5

You can then use them to test the neural network. The workflow I
prefer uses the "evalNN_keras.py" script to first evaluate the test
set and store the result in an sql database which can then be queried
to calculate different metrics.

$ python2 evalNN_keras.py --help
usage: evalNN_keras.py [-h] --input INPUT --model MODEL --weights WEIGHTS
                       --config CONFIG --output OUTPUT --normalization
                       NORMALIZATION

The --config file is the same as for the training script, but the
metadata block is saved in the ouput database.

$ python2 evalNN_keras.py --input $TEST_INPUT --model test.model.yaml \
    --weights test.weights.hdf5 --normalization test.normalization.txt \
    --output test.db --config <(python2 genconfig.py --type number)

This should create an sqlite3 database at "test.db", which can then be
input to the test-driver script which will create validation plots:

$ test-driver number test.db test.root

##### TODO ####################

* Add script to randomly generate NN hyperparameters configurations
* Add driver script for optimization